{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f009658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import date_format\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .master('local[*]') \\\n",
    "    .config(\"spark.driver.memory\", \"15g\") \\\n",
    "    .appName('TimeSeries') \\\n",
    "    .getOrCreate()\n",
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "\n",
    "# Load data from a CSV file into a DataFrame\n",
    "df_merged = spark.read.csv(\"/Users/andrewrenga/Documents/GW Senior Year/Semester 2/Capstone/df_merged.csv\", header=True, inferSchema=True)\n",
    "df_merged = df_merged.withColumn('MONTHLY REPORTING PERIOD', date_format('MONTHLY REPORTING PERIOD', 'yyyy-MM'))\n",
    "df_merged.show(10, truncate=False, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1325750f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit, expr, row_number, monotonically_increasing_id, when, col, first\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "import numpy as np\n",
    "#pip install tqdm\n",
    "from tqdm import tqdm\n",
    "\n",
    "df_merged_subset = df_merged.withColumn(\"Source\", lit(\"orig\"))\n",
    "df_merged_subset = df_merged_subset.withColumn(\"Horizon\", lit(0))\n",
    "df_merged_subset = df_merged_subset.withColumn(\"Group\", monotonically_increasing_id())\n",
    "\n",
    "# Define a window specification\n",
    "window_spec = Window.partitionBy(\"LOAN SEQUENCE NUMBER\").orderBy(\"LOAN AGE\")\n",
    "\n",
    "# Create an empty DataFrame to store the result\n",
    "result_df = df_merged_subset.sparkSession.createDataFrame([], df_merged_subset.schema)\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for row in tqdm(df_merged_subset.collect()):\n",
    "    # Add the original row to the result DataFrame\n",
    "    result_df = result_df.union(df_merged_subset.sparkSession.createDataFrame([row], df_merged_subset.schema))\n",
    "    if row['Source'] == 'orig':  # Check if 'Source' = 'orig'\n",
    "        # Duplicate the row 24 times\n",
    "        duplicated_rows = df_merged_subset.sparkSession.createDataFrame([row]*24, df_merged_subset.schema)\n",
    "        # Mark as 'Duplicated'\n",
    "        duplicated_rows = duplicated_rows.withColumn(\"Source\", lit(\"Duplicated\"))\n",
    "        # Add 'Horizon' column and label each duplicated row from 1 to 24\n",
    "        duplicated_rows = duplicated_rows.withColumn(\"Horizon\", (row_number().over(window_spec) - 1) % 24 + 1)\n",
    "        # Nullify other columns for Duplicated rows\n",
    "        exclude_cols = ['LOAN SEQUENCE NUMBER','Source', 'Horizon','Group']\n",
    "        # Apply the condition to each column\n",
    "        for col_name in duplicated_rows.columns:\n",
    "            if col_name not in exclude_cols:\n",
    "                duplicated_rows = duplicated_rows.withColumn(col_name, when(duplicated_rows[\"Source\"] == \"Duplicated\", None).otherwise(col(col_name)))\n",
    "        # Add the duplicated rows to the result DataFrame\n",
    "        result_df = result_df.union(duplicated_rows)\n",
    "\n",
    "df_merged_skinny = result_df.select(\"LOAN SEQUENCE NUMBER\", \"CREDIT SCORE\", \"LOAN AGE\", \"DEFAULT\", \"Horizon\", \"Source\", \"Group\")\n",
    "\n",
    "\n",
    "#### Adding correct Default value to each horizon\n",
    "\n",
    "# Find the default values when Source = 'orig' for each group\n",
    "default_values_df = df_merged_skinny.filter(col(\"Source\") == \"orig\") \\\n",
    "    .withColumn(\"default_value\", first(col(\"DEFAULT\")).over(window_spec)) \\\n",
    "    .select(\"LOAN SEQUENCE NUMBER\", \"Group\", \"default_value\")\n",
    "\n",
    "# Join the default values back to the df_merged_skinny DataFrame\n",
    "df_merged_skinny = df_merged_skinny.join(default_values_df, on=[\"LOAN SEQUENCE NUMBER\", \"Group\"], how=\"left\")\n",
    "\n",
    "# Fill DEFAULT column for 'Duplicated' rows with the DEFAULT value from 'orig' rows in the same group\n",
    "df_merged_skinny = df_merged_skinny.withColumn(\"DEFAULT\", when(df_merged_skinny[\"Source\"] == \"Duplicated\", \n",
    "                                                              col(\"default_value\"))\n",
    "                                               .otherwise(col(\"DEFAULT\")))\n",
    "\n",
    "# Drop the temporary column default_value\n",
    "df_merged_skinny = df_merged_skinny.drop(\"default_value\")\n",
    "\n",
    "df_merged_skinny.show(3, truncate=False, vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6912a16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, col, lit\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Calculate the static LOAN AGE value when Source = 'orig' for each group\n",
    "static_loan_age_df = df_merged_skinny.filter(col(\"Source\") == \"orig\") \\\n",
    "    .groupBy(\"Group\").agg({\"LOAN AGE\": \"first\"}) \\\n",
    "    .withColumnRenamed(\"first(LOAN AGE)\", \"static_LOAN_AGE\")\n",
    "\n",
    "# Join static_loan_age_df to df_merged_skinny based on the \"Group\" column\n",
    "result_df1 = df_merged_skinny.join(static_loan_age_df, on=\"Group\")\n",
    "\n",
    "# Define a window specification\n",
    "window_spec = Window.partitionBy(\"Group\").orderBy(\"Horizon\")\n",
    "\n",
    "# Subtract the static LOAN AGE value by the 'Horizon' value for each row within the same group\n",
    "result_df1 = result_df1.withColumn(\"LOAN AGE\", \n",
    "                                 when(col(\"Source\") == \"Duplicated\", \n",
    "                                      col(\"static_LOAN_AGE\") - col(\"Horizon\"))\n",
    "                                 .otherwise(col(\"LOAN AGE\")))\n",
    "\n",
    "# Drop the static_LOAN_AGE column and keep rows where loan age >= 0 \n",
    "result_df1 = result_df1.drop(\"static_LOAN_AGE\")\n",
    "result_df1 = result_df1[result_df1['LOAN AGE'] >= 0]\n",
    "\n",
    "df_merged_skinny = result_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada36d07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Left join df_merged into df_merged_skinny based on matching columns\n",
    "df_merged_skinny = df_merged_skinny.withColumnRenamed(\"LOAN SEQUENCE NUMBER\", \"LOAN SEQUENCE NUMBER 1\") \\\n",
    "                                   .withColumnRenamed(\"CREDIT SCORE\", \"CREDIT SCORE 1\") \\\n",
    "                                   .withColumnRenamed(\"LOAN AGE\", \"LOAN AGE 1\") \\\n",
    "                                   .withColumnRenamed(\"DEFAULT\", \"DEFAULT_orig\")\n",
    "\n",
    "df_timeseries = df_merged_skinny.join(df_merged, \n",
    "                                   (df_merged_skinny[\"LOAN SEQUENCE NUMBER 1\"] == df_merged[\"LOAN SEQUENCE NUMBER\"]) &\n",
    "                                   (df_merged_skinny[\"LOAN AGE 1\"] == df_merged[\"LOAN AGE\"]), \n",
    "                                   \"left\")\n",
    "\n",
    "# Drop duplicated columns and rename DEFAULT_orig back to DEFAULT\n",
    "df_timeseries = df_timeseries.drop(\"LOAN SEQUENCE NUMBER 1\", \"CREDIT SCORE 1\", \"LOAN AGE 1\", \"DEFAULT\")\n",
    "df_timeseries = df_timeseries.withColumnRenamed(\"DEFAULT_orig\", \"DEFAULT\") \\\n",
    "\n",
    "# Show the joined DataFrame\n",
    "pandas_df = df_timeseries.toPandas()\n",
    "\n",
    "# Print the pandas DataFrame\n",
    "pandas_df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
